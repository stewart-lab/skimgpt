{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "# 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EuzyiSTCNQ0l",
    "outputId": "12c9129b-fbf7-4f3c-f178-56415db5aaca",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.82)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.3.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.42.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.32.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.23.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.5.82)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.4)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (3.11.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.7.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (68.2.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.8.6)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.3.0)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.42.3)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl) (1.24.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.32.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl) (2.20.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.8.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.5.82)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2024.5.15)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (4.66.4)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl) (5.9.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2022.12.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.24.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-py56a5kn/unsloth_dc96b2e9f4f1496fa8963263cde93b45\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-py56a5kn/unsloth_dc96b2e9f4f1496fa8963263cde93b45\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit 4be284bd79d2c4ffab378b93d7282b54f96647e9\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.43.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.24.1)\n",
      "Collecting xformers@ https://download.pytorch.org/whl/cu118/xformers-0.0.26.post1%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl (from unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Using cached https://download.pytorch.org/whl/cu118/xformers-0.0.26.post1%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl (222.9 MB)\n",
      "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.8.5)\n",
      "Requirement already satisfied: transformers>=4.42.3 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.42.3)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.20.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (5.9.6)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n",
      "Requirement already satisfied: accelerate>=0.26.1 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.32.1)\n",
      "Requirement already satisfied: trl<0.9.0,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.8.6)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.11.1)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (23.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.5.82)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.3->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.3->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (2022.12.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth[cu118-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
      "Installing collected packages: xformers\n",
      "  Attempting uninstall: xformers\n",
      "    Found existing installation: xformers 0.0.26.post1\n",
      "    Uninstalling xformers-0.0.26.post1:\n",
      "      Successfully uninstalled xformers-0.0.26.post1\n",
      "Successfully installed xformers-0.0.26.post1+cu118\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-qzyjkxv7/unsloth_72aae449478f44efb4075e332617b02d\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-qzyjkxv7/unsloth_72aae449478f44efb4075e332617b02d\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit 4be284bd79d2c4ffab378b93d7282b54f96647e9\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.43.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.24.1)\n",
      "Collecting xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (from unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n",
      "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.8.5)\n",
      "Requirement already satisfied: transformers>=4.42.3 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.42.3)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.20.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (5.9.6)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n",
      "Requirement already satisfied: accelerate>=0.26.1 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.32.1)\n",
      "Requirement already satisfied: trl<0.9.0,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.8.6)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.11.1)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (23.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.5.82)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.3->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.3->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2022.12.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
      "Installing collected packages: xformers\n",
      "  Attempting uninstall: xformers\n",
      "    Found existing installation: xformers 0.0.26.post1+cu118\n",
      "    Uninstalling xformers-0.0.26.post1+cu118:\n",
      "      Successfully uninstalled xformers-0.0.26.post1+cu118\n",
      "Successfully installed xformers-0.0.26.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-nub9mdd2/unsloth_7dbd72b917854d779faf5734016aa109\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-nub9mdd2/unsloth_7dbd72b917854d779faf5734016aa109\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit 4be284bd79d2c4ffab378b93d7282b54f96647e9\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.43.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (23.2)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.11.1.1)\n",
      "Requirement already satisfied: flash-attn in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.5.9.post1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.24.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.8.0)\n",
      "Collecting xformers@ https://download.pytorch.org/whl/cu118/xformers-0.0.26.post1%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Using cached https://download.pytorch.org/whl/cu118/xformers-0.0.26.post1%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl (222.9 MB)\n",
      "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.8.5)\n",
      "Requirement already satisfied: transformers>=4.42.3 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.42.3)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.20.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (5.9.6)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n",
      "Requirement already satisfied: accelerate>=0.26.1 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.32.1)\n",
      "Requirement already satisfied: trl<0.9.0,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.8.6)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.11.1)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.5.82)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.3->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.3->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2022.12.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth[cu118-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
      "Installing collected packages: xformers\n",
      "  Attempting uninstall: xformers\n",
      "    Found existing installation: xformers 0.0.26.post1\n",
      "    Uninstalling xformers-0.0.26.post1:\n",
      "      Successfully uninstalled xformers-0.0.26.post1\n",
      "Successfully installed xformers-0.0.26.post1+cu118\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-c2szpzoq/unsloth_3fd2eb63062f487ab6e078dc656bb12f\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-c2szpzoq/unsloth_3fd2eb63062f487ab6e078dc656bb12f\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit 4be284bd79d2c4ffab378b93d7282b54f96647e9\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.43.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (23.2)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.11.1.1)\n",
      "Requirement already satisfied: flash-attn in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.5.9.post1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.24.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.8.0)\n",
      "Collecting xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n",
      "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.8.5)\n",
      "Requirement already satisfied: transformers>=4.42.3 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.42.3)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.20.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (5.9.6)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n",
      "Requirement already satisfied: accelerate>=0.26.1 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.32.1)\n",
      "Requirement already satisfied: trl<0.9.0,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.8.6)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.11.1)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.1->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.5.82)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.3->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.3->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2022.12.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth[cu121-ampere-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
      "Installing collected packages: xformers\n",
      "  Attempting uninstall: xformers\n",
      "    Found existing installation: xformers 0.0.26.post1+cu118\n",
      "    Uninstalling xformers-0.0.26.post1+cu118:\n",
      "      Successfully uninstalled xformers-0.0.26.post1+cu118\n",
      "Successfully installed xformers-0.0.26.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.26.post1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.24.1)\n",
      "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->xformers) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->xformers) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0->xformers) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->xformers) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "!pip install peft\n",
    "!pip install wandb\n",
    "!pip install trl\n",
    "!pip install bitsandbytes\n",
    "!pip install scikit-learn\n",
    "!pip install \"unsloth[cu118-torch230] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install \"unsloth[cu121-torch230] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install \"unsloth[cu118-ampere-torch230] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install \"unsloth[cu121-ampere-torch230] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grIXo24axlGk",
    "outputId": "e6f2e82b-f48c-4f67-a2cd-ad9459ba7d28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flash-attn in /usr/local/lib/python3.10/dist-packages (2.5.9.post1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.3.0)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.8.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GXsaEAu0uBZo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import wandb\n",
    "import transformers\n",
    "import torch\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from unsloth import FastLanguageModel\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "from torch import nn\n",
    "import sys\n",
    "import gc\n",
    "from transformers import AdamW\n",
    "from accelerate import notebook_launcher\n",
    "from sklearn.model_selection import train_test_split\n",
    "from accelerate import DistributedDataParallelKwargs\n",
    "import time\n",
    "import re\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from transformers import TrainingArguments, BitsAndBytesConfig\n",
    "import accelerate\n",
    "import json\n",
    "from peft import IA3Config, IA3Model, LoraConfig\n",
    "import jinja2\n",
    "import math\n",
    "import bitsandbytes as bnb\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import math\n",
    "from trl import setup_chat_format\n",
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "# From this Gist: https://gist.github.com/ihoromi4/b681a9088f348942b01711f251e5f964\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1On8ZTnggTen",
    "outputId": "e5a3956c-ea7c-4c73-e0e8-82a00995d995",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/huggingface-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/huggingface_cli.py\", line 51, in main\n",
      "    service.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/user.py\", line 98, in run\n",
      "    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/_login.py\", line 111, in login\n",
      "    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/_login.py\", line 307, in _login\n",
      "    raise ValueError(\"Invalid token passed!\")\n",
      "ValueError: Invalid token passed!\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xzJk4KGHPJR4",
    "outputId": "192227cd-e669-49a2-d121-3488f473d120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login 4a376fd0ab1c0901b9d9886d0734a88b4794a7fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "86pTN-0BdLAy"
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    # General Configuration\n",
    "    device_type = \"gpus\"\n",
    "    model = \"unsloth/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "    # Training Configuration\n",
    "    max_seq_length = 2048\n",
    "    trust = True\n",
    "\n",
    "    # Porpoise One (Relevance Filtering Parameters)\n",
    "    ab_hypothesis = \"There exists an interaction between the disease {a_term} and the gene {b_term}.\"\n",
    "    bc_hypothesis = \"There exists an interaction between the drug {c_term} and the gene {b_term}.\"\n",
    "    ac_hypothesis = \"The drug {c_term} has an interaction with the disease {a_term}.\"\n",
    "\n",
    "    rel_instr = \"Classify this abstract as either 0 (Not Relevant) or 1 (Relevant) for evaluating the provided hypothesis.\"\n",
    "\n",
    "    # Porpoise Two (Supports parameters)\n",
    "    sup_instr = \"Explain why (or why not) this biomedical abstract supports the provided statement. Give a score of 1 for supports and a score of 0 for does not support.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevance data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sNRSV5hfQW81"
   },
   "outputs": [],
   "source": [
    "def train_ans_prompt(hyp, abstract, instr, label, cot) -> str:\n",
    "\treturn f\"Abstract: {abstract}\\nHypothesis: {hyp}\\nInstructions: {config.rel_instr}\\nScore: {label}\\nExplanation: {cot}\"\n",
    "\n",
    "def test_ans_prompt(hyp, abstract, instr, label) -> str:\n",
    "\treturn f\"Abstract: {abstract}\\nHypothesis: {hyp}\\nInstructions: {config.rel_instr}\\nScore: {label}\"\n",
    "\n",
    "def eval_ans_prompt(hyp, abstract, instr) -> str:\n",
    "\treturn f\"Abstract: {abstract}\\nHypothesis: {hyp}\\nInstructions: {config.rel_instr}\\nScore: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YJrAejGQ0gfB"
   },
   "outputs": [],
   "source": [
    "train_rel = pd.read_csv(\"./data/Porpoise_1/same_dist_train.tsv\", sep=\"\\t\")\n",
    "test_rel = pd.read_csv(\"./data/Porpoise_1/same_dist_test.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RqvJzlex1qdO"
   },
   "outputs": [],
   "source": [
    "def processRowTrainText(row, prompt_fn):\n",
    "    if pd.isnull(row[\"a_term\"]):\n",
    "        hypothesis = config.bc_hypothesis.format(c_term=row[\"c_term\"], b_term=row[\"b_term\"])\n",
    "    elif pd.isnull(row[\"b_term\"]):\n",
    "        hypothesis = config.ac_hypothesis.format(c_term=row[\"c_term\"], a_term=row[\"a_term\"])\n",
    "    elif pd.isnull(row[\"c_term\"]):\n",
    "        hypothesis = config.ab_hypothesis.format(a_term=row[\"a_term\"], b_term=row[\"b_term\"])\n",
    "    return prompt_fn(hypothesis, row[\"abstract\"], config.rel_instr, int(row[\"label\"]), row[\"cot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2f3iNfOSgTeq"
   },
   "outputs": [],
   "source": [
    "def processRowTestText(row, prompt_fn):\n",
    "    if pd.isnull(row[\"a_term\"]):\n",
    "        hypothesis = config.bc_hypothesis.format(c_term=row[\"c_term\"], b_term=row[\"b_term\"])\n",
    "    elif pd.isnull(row[\"b_term\"]):\n",
    "        hypothesis = config.ac_hypothesis.format(c_term=row[\"c_term\"], a_term=row[\"a_term\"])\n",
    "    elif pd.isnull(row[\"c_term\"]):\n",
    "        hypothesis = config.ab_hypothesis.format(a_term=row[\"a_term\"], b_term=row[\"b_term\"])\n",
    "    return prompt_fn(hypothesis, row[\"abstract\"], config.rel_instr, int(row[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NFjizwxhpLEW"
   },
   "outputs": [],
   "source": [
    "def processRowPrompt(row, prompt_fn):\n",
    "    if pd.isnull(row[\"a_term\"]):\n",
    "        hypothesis = config.bc_hypothesis.format(c_term=row[\"c_term\"], b_term=row[\"b_term\"])\n",
    "    elif pd.isnull(row[\"b_term\"]):\n",
    "        hypothesis = config.ac_hypothesis.format(c_term=row[\"c_term\"], a_term=row[\"a_term\"])\n",
    "    elif pd.isnull(row[\"c_term\"]):\n",
    "        hypothesis = config.ab_hypothesis.format(a_term=row[\"a_term\"], b_term=row[\"b_term\"])\n",
    "    return prompt_fn(hypothesis, row[\"abstract\"], config.rel_instr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2GNiRFzM0sf5"
   },
   "outputs": [],
   "source": [
    "train_rel[\"text\"] = train_rel.apply(lambda row: processRowTrainText(row, train_ans_prompt), axis=1)\n",
    "train_rel[\"prompt\"] = train_rel.apply(lambda row: processRowPrompt(row, eval_ans_prompt), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AfhPnZBELFTd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_rel[\"text\"] = test_rel.apply(lambda row: processRowTestText(row, test_ans_prompt), axis=1)\n",
    "test_rel[\"prompt\"] = test_rel.apply(lambda row: processRowPrompt(row, eval_ans_prompt), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText(row):\n",
    "    return f'Abstract: {row[\"abstract\"]}\\nStatement: {row[\"statement\"]}\\nInstructions: {config.sup_instr}\\nScore: {row[\"label\"]}\\nExplanation: {row[\"cot\"]}'\n",
    "\n",
    "def getPrompt(row):\n",
    "    return f'Abstract: {row[\"abstract\"]}\\nStatement: {row[\"statement\"]}\\nInstructions: {config.sup_instr}\\nScore: '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sup = pd.read_csv(\"./data/Porpoise_2/train.tsv\", sep = \"\\t\")\n",
    "test_sup = pd.read_csv(\"./data/Porpoise_2/test.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sup[\"text\"] = train_sup.apply(lambda row: getText(row), axis = 1)\n",
    "train_sup[\"prompt\"] = train_sup.apply(lambda row: getPrompt(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sup[\"text\"] = test_sup.apply(lambda row: getText(row), axis = 1)\n",
    "test_sup[\"prompt\"] = test_sup.apply(lambda row: getPrompt(row), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = pd.concat([train_sup[\"text\"], train_rel[\"text\"]], ignore_index = True)\n",
    "train_prompts = pd.concat([train_sup[\"prompt\"], train_rel[\"prompt\"]], ignore_index = True)\n",
    "\n",
    "test_text = pd.concat([test_sup[\"text\"], test_rel[\"text\"]], ignore_index = True)\n",
    "test_prompts = pd.concat([test_sup[\"prompt\"], test_rel[\"prompt\"]], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame({\"text\": train_text, \"prompt\": train_prompts})\n",
    "test = pd.DataFrame({\"text\": test_text, \"prompt\": test_prompts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Dataset.from_pandas(train)\n",
    "test = Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZEPpusOVNUQ"
   },
   "source": [
    "# 3. Sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.integrations import WandbCallback\n",
    "class LLMSampleCB(WandbCallback):\n",
    "    def __init__(self, trainer, test_sup, test_rel):\n",
    "        super().__init__()\n",
    "        self.test_rel = test_rel\n",
    "        self.test_sup = test_sup\n",
    "        \n",
    "        self.y_sup = torch.tensor(self.test_sup[\"label\"])\n",
    "        self.y_rel = torch.tensor(self.test_rel[\"label\"])\n",
    "        \n",
    "        self.model, self.tokenizer = trainer.model, trainer.tokenizer\n",
    "        self.trainer = trainer\n",
    "\n",
    "    def get_metrics(self, test_set, labels):\n",
    "        FastLanguageModel.for_inference(self.model)\n",
    "        y_hat = []\n",
    "        for i in tqdm(range(len(test_set[\"prompt\"]))):\n",
    "            prompt = test_set[\"prompt\"][i]\n",
    "            prompt_ids = self.tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
    "            out = self.model.generate(prompt_ids.cuda(), max_new_tokens = 1)[-1]\n",
    "            response = self.tokenizer.decode(out)\n",
    "            try:\n",
    "                score = int(response[-1])\n",
    "            except:\n",
    "                score = 1 - labels[i]\n",
    "            y_hat.append(score)\n",
    "\n",
    "        y_hat = torch.tensor(y_hat)\n",
    "\n",
    "        acc = accuracy_score(labels, y_hat)\n",
    "        prec = precision_score(labels, y_hat, average='weighted')\n",
    "        recall = recall_score(labels, y_hat, average='weighted')\n",
    "        f1 = f1_score(labels, y_hat, average='weighted')\n",
    "\n",
    "        return acc, prec, recall, f1\n",
    "\n",
    "    def log(self, acc, prec, recall, f1, title):\n",
    "        epoch = math.ceil(self.trainer.state.epoch)\n",
    "        self._wandb.log({f\"{title} Running Validation Accuracy\": acc})\n",
    "        self._wandb.log({f\"{title} Running Validation Precision\": prec})\n",
    "        self._wandb.log({f\"{title} Running Validation Recall\": recall})\n",
    "        self._wandb.log({f\"{title} Running Validation F1-Score\": f1})\n",
    "        print(f\"*********** {title} RESULTS ***********\")\n",
    "        print(f\"Epoch {epoch}:\\n\\tAccuracy: {acc:.3f}\\n\\tPrecision: {prec:.3f}\\n\\tRecall: {recall:.3f}\\n\\tF-1 Score: {f1:.3f}\")\n",
    "\n",
    "    def avg(self, num1, num2):\n",
    "        return (num1 + num2) / 2.0\n",
    "        \n",
    "    def on_evaluate(self, args, state, control,  **kwargs):\n",
    "        super().on_evaluate(args, state, control, **kwargs)\n",
    "        acc_rel, prec_rel, recall_rel, f1_rel = self.get_metrics(self.test_rel, self.y_rel)\n",
    "        acc_sup, prec_sup, recall_sup, f1_sup = self.get_metrics(self.test_sup, self.y_sup)\n",
    "\n",
    "        self.log(acc_rel, prec_rel, recall_rel, f1_rel, \"Relevance\")\n",
    "        self.log(acc_sup, prec_sup, recall_sup, f1_sup, \"Support\")\n",
    "\n",
    "        acc_avg = self.avg(acc_rel, acc_sup)\n",
    "        prec_avg = self.avg(prec_rel, prec_sup)\n",
    "        recall_avg = self.avg(recall_rel, recall_sup)\n",
    "        f1_avg = self.avg(f1_rel, f1_sup)\n",
    "\n",
    "        self.log(acc_avg, prec_avg, recall_avg, f1_avg, \"Average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_predictions(test_set, tokenizer, trainer):\n",
    "    with torch.inference_mode():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            y_hat = []\n",
    "            cots = []\n",
    "            num_wrong = 0\n",
    "            for i in tqdm(range(len(test_set[\"prompt\"]))):\n",
    "                prompt = test_set[\"prompt\"][i]\n",
    "                prompt_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
    "                out = trainer.model.generate(prompt_ids.cuda(), max_new_tokens = 1)\n",
    "                response = tokenizer.decode(out[0])\n",
    "                score = int(response[-1])\n",
    "                cot = \"Correct! So no explanation was given.\"\n",
    "    \n",
    "                if score != test_set[\"label\"][i]:\n",
    "                    rationale = trainer.model.generate(prompt_ids.cuda(), max_new_tokens = 10)\n",
    "                    rationale = tokenizer.decode(rationale[0])\n",
    "                    prompt, ans = rationale.split(\"Score: \")\n",
    "                    cot = ans[1:]\n",
    "                    num_wrong += 1\n",
    "                    print(\"wrong\")\n",
    "                \n",
    "                y_hat.append(score)\n",
    "                cots.append(cot)\n",
    "    return y_hat, cots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_table(test_set, y_hat, y, cots, title):\n",
    "    data = list(zip(test_set[\"prompt\"], y_hat, y, cots))\n",
    "    test_table = wandb.Table(columns = [\"prompt\", \"y_hat\", \"y\", \"rationale\"], data = data)\n",
    "    wandb.log({f\"{title}\": test_table})\n",
    "\n",
    "def conf_mat(y_hat, y, title, class_names):\n",
    "    wandb.log({f\"{title}\": wandb.plot.confusion_matrix(y_true=y.tolist(), preds=y_hat.tolist(), class_names=class_names, title = title)})\n",
    "\n",
    "def avg_scores(y_hat_rel, y_hat_sup, y_rel, y_sup):\n",
    "\n",
    "    rel_acc = accuracy_score(y_rel, y_hat_rel)\n",
    "    rel_prec = precision_score(y_rel, y_hat_rel, average='weighted')\n",
    "    rel_recall = recall_score(y_rel, y_hat_rel, average='weighted')\n",
    "    rel_f1 = f1_score(y_rel, y_hat_rel, average='weighted')\n",
    "\n",
    "    sup_acc = accuracy_score(y_sup, y_hat_sup)\n",
    "    sup_prec = precision_score(y_sup, y_hat_sup, average='weighted')\n",
    "    sup_recall = recall_score(y_sup, y_hat_sup, average='weighted')\n",
    "    sup_f1 = f1_score(y_sup, y_hat_sup, average='weighted')\n",
    "\n",
    "    avg_acc = (rel_acc + sup_acc) / 2.0\n",
    "    avg_prec = (rel_prec + sup_prec) / 2.0\n",
    "    avg_recall = (rel_recall + sup_recall) / 2.0\n",
    "    avg_f1 = (rel_f1 + sup_f1) / 2.0\n",
    "\n",
    "    wandb.log({\"Average Validation Accuracy\": avg_acc})\n",
    "    wandb.log({\"Average Validation Precision\": avg_prec})\n",
    "    wandb.log({\"Average Validation Recall\": avg_recall})\n",
    "    wandb.log({\"Average Validation F1-Score\": avg_f1})\n",
    "    \n",
    "    print(f\"Average Validation Accuracy: {avg_acc}\")\n",
    "    print(f\"Average Validation Precision: {avg_prec}\")\n",
    "    print(f\"Average Validation Recall: {avg_recall}\")\n",
    "    print(f\"Average Validation F1-Score: {avg_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Eval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    with wandb.init(project=\"kmGPT\", entity = \"morgridge\", group = \"Porpoise 2.0\", name = \"Hyperband Sweep\"):\n",
    "        hyp_config = wandb.config\n",
    "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "            model_name = config.model,\n",
    "            max_seq_length = config.max_seq_length,\n",
    "            load_in_4bit = True,\n",
    "            trust_remote_code = config.trust,\n",
    "            attn_implementation = 'flash_attention_2',\n",
    "            device_map = \"auto\",\n",
    "        )\n",
    "        \n",
    "        model = FastLanguageModel.get_peft_model(\n",
    "            model,\n",
    "            target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "            r = hyp_config.rank,\n",
    "            lora_alpha = hyp_config.lora_alpha,\n",
    "            lora_dropout = 0.0,\n",
    "            bias = \"none\",\n",
    "            use_rslora = True,\n",
    "            loftq_config = None\n",
    "        )\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = \"checkpoints\",\n",
    "            report_to = \"wandb\",\n",
    "            learning_rate = 2e-4,\n",
    "            warmup_ratio = 0.03,\n",
    "            lr_scheduler_type = \"cosine\",\n",
    "            num_train_epochs = hyp_config.epochs,\n",
    "            per_device_train_batch_size = 2,\n",
    "            gradient_accumulation_steps = 8,\n",
    "            bf16 = True,\n",
    "            optim = \"paged_adamw_8bit\",\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy = \"epoch\",\n",
    "            logging_steps = 1,\n",
    "            do_eval=True,\n",
    "            neftune_noise_alpha = hyp_config.neftune,\n",
    "            weight_decay = 0.01,\n",
    "        )\n",
    "\n",
    "        trainer = SFTTrainer(\n",
    "            args = training_args,\n",
    "            model=model,\n",
    "            # peft_config=peft_config,\n",
    "            # data_collator=DataCollatorForCompletionOnlyLM(response_template_ids, tokenizer = tokenizer),\n",
    "            packing = True,\n",
    "            train_dataset=train,\n",
    "            eval_dataset=test,\n",
    "            dataset_text_field=\"text\",\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_length=2048,\n",
    "        )\n",
    "        \n",
    "        wandb_callback = LLMSampleCB(trainer, test_sup, test_rel)\n",
    "        trainer.add_callback(wandb_callback)\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        y_hat_rel, cots_rel = gather_predictions(test_rel, tokenizer, trainer)\n",
    "        y_hat_sup, cots_sup = gather_predictions(test_sup, tokenizer, trainer)\n",
    "        \n",
    "        y_rel, y_hat_rel = torch.tensor(test_rel[\"label\"]), torch.tensor(y_hat_rel)\n",
    "        y_sup, y_hat_sup = torch.tensor(test_sup[\"label\"]), torch.tensor(y_hat_sup)\n",
    "\n",
    "        pred_table(test_rel, y_hat_rel, y_rel, cots_rel, \"Relevance Predictions\")\n",
    "        pred_table(test_sup, y_hat_sup, y_sup, cots_sup, \"Support Predictions\")\n",
    "\n",
    "        conf_mat(y_hat_rel, y_rel, \"Relevance Confusion Matrix\", [\"Irrelevant\", \"Relevant\"])\n",
    "        conf_mat(y_hat_sup, y_sup, \"Support Confusion Matrix\", [\"Unsupportive\", \"Supportive\"])\n",
    "\n",
    "        avg_scores(y_hat_rel, y_hat_sup, y_rel, y_sup)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kickoff Sweep!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"Porpoise 2.0 Sweep\",\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"goal\": \"maximize\", \"name\": \"Average Running Validation F1-Score\", \"target\": 0.95},\n",
    "    \"parameters\": {\n",
    "        \"rank\": {\"values\": [2, 4, 8, 16, 32, 64, 128]},\n",
    "        \"lora_alpha\": {\"values\": [4, 8, 16, 32, 64, 128, 256]},\n",
    "        \"neftune\": {\"values\": [0, 5, 10, 15]},\n",
    "        \"epochs\": {\"values\": [5, 10, 15]},\n",
    "    },\n",
    "    \"early_terminate\": {\n",
    "        \"type\": \"hyperband\",\n",
    "        \"min_iter\": 2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: tf4q3apm\n",
      "Sweep URL: https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: myj7rgrb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mleoxu27\u001b[0m (\u001b[33mmorgridge\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_230628-myj7rgrb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/myj7rgrb' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/myj7rgrb' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/myj7rgrb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 75 | Num Epochs = 15\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 16 | Total steps = 60\n",
      " \"-____-\"     Number of trainable parameters = 3,735,552\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 12:54, Epoch 12/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.249100</td>\n",
       "      <td>1.268026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.151000</td>\n",
       "      <td>1.174084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.069600</td>\n",
       "      <td>1.149517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.988300</td>\n",
       "      <td>1.145904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.966100</td>\n",
       "      <td>1.152850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.884500</td>\n",
       "      <td>1.165716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.823800</td>\n",
       "      <td>1.194880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.831400</td>\n",
       "      <td>1.206556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.786200</td>\n",
       "      <td>1.215304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.821400</td>\n",
       "      <td>1.218774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/72 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "100%|██████████| 72/72 [00:07<00:00,  9.45it/s]\n",
      "100%|██████████| 40/40 [00:04<00:00,  9.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Relevance RESULTS ***********\n",
      "Epoch 1:\n",
      "\tAccuracy: 0.708\n",
      "\tPrecision: 0.691\n",
      "\tRecall: 0.708\n",
      "\tF-1 Score: 0.687\n",
      "*********** Support RESULTS ***********\n",
      "Epoch 1:\n",
      "\tAccuracy: 0.875\n",
      "\tPrecision: 0.884\n",
      "\tRecall: 0.875\n",
      "\tF-1 Score: 0.874\n",
      "*********** Average RESULTS ***********\n",
      "Epoch 1:\n",
      "\tAccuracy: 0.792\n",
      "\tPrecision: 0.787\n",
      "\tRecall: 0.792\n",
      "\tF-1 Score: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:07<00:00,  9.80it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Relevance RESULTS ***********\n",
      "Epoch 2:\n",
      "\tAccuracy: 0.778\n",
      "\tPrecision: 0.805\n",
      "\tRecall: 0.778\n",
      "\tF-1 Score: 0.746\n",
      "*********** Support RESULTS ***********\n",
      "Epoch 2:\n",
      "\tAccuracy: 0.875\n",
      "\tPrecision: 0.900\n",
      "\tRecall: 0.875\n",
      "\tF-1 Score: 0.873\n",
      "*********** Average RESULTS ***********\n",
      "Epoch 2:\n",
      "\tAccuracy: 0.826\n",
      "\tPrecision: 0.853\n",
      "\tRecall: 0.826\n",
      "\tF-1 Score: 0.810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:06<00:00, 10.51it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Relevance RESULTS ***********\n",
      "Epoch 3:\n",
      "\tAccuracy: 0.806\n",
      "\tPrecision: 0.807\n",
      "\tRecall: 0.806\n",
      "\tF-1 Score: 0.794\n",
      "*********** Support RESULTS ***********\n",
      "Epoch 3:\n",
      "\tAccuracy: 0.875\n",
      "\tPrecision: 0.876\n",
      "\tRecall: 0.875\n",
      "\tF-1 Score: 0.875\n",
      "*********** Average RESULTS ***********\n",
      "Epoch 3:\n",
      "\tAccuracy: 0.840\n",
      "\tPrecision: 0.841\n",
      "\tRecall: 0.840\n",
      "\tF-1 Score: 0.834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:07<00:00,  9.97it/s]\n",
      "100%|██████████| 40/40 [00:04<00:00,  9.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Relevance RESULTS ***********\n",
      "Epoch 4:\n",
      "\tAccuracy: 0.806\n",
      "\tPrecision: 0.814\n",
      "\tRecall: 0.806\n",
      "\tF-1 Score: 0.789\n",
      "*********** Support RESULTS ***********\n",
      "Epoch 4:\n",
      "\tAccuracy: 0.875\n",
      "\tPrecision: 0.900\n",
      "\tRecall: 0.875\n",
      "\tF-1 Score: 0.873\n",
      "*********** Average RESULTS ***********\n",
      "Epoch 4:\n",
      "\tAccuracy: 0.840\n",
      "\tPrecision: 0.857\n",
      "\tRecall: 0.840\n",
      "\tF-1 Score: 0.831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:06<00:00, 10.39it/s]\n",
      "100%|██████████| 40/40 [00:04<00:00,  9.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Relevance RESULTS ***********\n",
      "Epoch 5:\n",
      "\tAccuracy: 0.847\n",
      "\tPrecision: 0.852\n",
      "\tRecall: 0.847\n",
      "\tF-1 Score: 0.839\n",
      "*********** Support RESULTS ***********\n",
      "Epoch 5:\n",
      "\tAccuracy: 0.900\n",
      "\tPrecision: 0.904\n",
      "\tRecall: 0.900\n",
      "\tF-1 Score: 0.900\n",
      "*********** Average RESULTS ***********\n",
      "Epoch 5:\n",
      "\tAccuracy: 0.874\n",
      "\tPrecision: 0.878\n",
      "\tRecall: 0.874\n",
      "\tF-1 Score: 0.870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:07<00:00, 10.01it/s]\n",
      "100%|██████████| 40/40 [00:04<00:00,  9.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Relevance RESULTS ***********\n",
      "Epoch 6:\n",
      "\tAccuracy: 0.861\n",
      "\tPrecision: 0.864\n",
      "\tRecall: 0.861\n",
      "\tF-1 Score: 0.855\n",
      "*********** Support RESULTS ***********\n",
      "Epoch 6:\n",
      "\tAccuracy: 0.875\n",
      "\tPrecision: 0.884\n",
      "\tRecall: 0.875\n",
      "\tF-1 Score: 0.874\n",
      "*********** Average RESULTS ***********\n",
      "Epoch 6:\n",
      "\tAccuracy: 0.868\n",
      "\tPrecision: 0.874\n",
      "\tRecall: 0.868\n",
      "\tF-1 Score: 0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:06<00:00, 10.53it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Relevance RESULTS ***********\n",
      "Epoch 7:\n",
      "\tAccuracy: 0.778\n",
      "\tPrecision: 0.789\n",
      "\tRecall: 0.778\n",
      "\tF-1 Score: 0.753\n",
      "*********** Support RESULTS ***********\n",
      "Epoch 7:\n",
      "\tAccuracy: 0.925\n",
      "\tPrecision: 0.926\n",
      "\tRecall: 0.925\n",
      "\tF-1 Score: 0.925\n",
      "*********** Average RESULTS ***********\n",
      "Epoch 7:\n",
      "\tAccuracy: 0.851\n",
      "\tPrecision: 0.857\n",
      "\tRecall: 0.851\n",
      "\tF-1 Score: 0.839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:07<00:00,  9.79it/s]\n",
      "100%|██████████| 40/40 [00:04<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Relevance RESULTS ***********\n",
      "Epoch 8:\n",
      "\tAccuracy: 0.778\n",
      "\tPrecision: 0.789\n",
      "\tRecall: 0.778\n",
      "\tF-1 Score: 0.753\n",
      "*********** Support RESULTS ***********\n",
      "Epoch 8:\n",
      "\tAccuracy: 0.900\n",
      "\tPrecision: 0.904\n",
      "\tRecall: 0.900\n",
      "\tF-1 Score: 0.900\n",
      "*********** Average RESULTS ***********\n",
      "Epoch 8:\n",
      "\tAccuracy: 0.839\n",
      "\tPrecision: 0.846\n",
      "\tRecall: 0.839\n",
      "\tF-1 Score: 0.826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:06<00:00, 10.49it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Relevance RESULTS ***********\n",
      "Epoch 9:\n",
      "\tAccuracy: 0.833\n",
      "\tPrecision: 0.839\n",
      "\tRecall: 0.833\n",
      "\tF-1 Score: 0.823\n",
      "*********** Support RESULTS ***********\n",
      "Epoch 9:\n",
      "\tAccuracy: 0.900\n",
      "\tPrecision: 0.904\n",
      "\tRecall: 0.900\n",
      "\tF-1 Score: 0.900\n",
      "*********** Average RESULTS ***********\n",
      "Epoch 9:\n",
      "\tAccuracy: 0.867\n",
      "\tPrecision: 0.872\n",
      "\tRecall: 0.867\n",
      "\tF-1 Score: 0.861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:07<00:00, 10.23it/s]\n",
      "100%|██████████| 40/40 [00:04<00:00,  9.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Relevance RESULTS ***********\n",
      "Epoch 10:\n",
      "\tAccuracy: 0.833\n",
      "\tPrecision: 0.839\n",
      "\tRecall: 0.833\n",
      "\tF-1 Score: 0.823\n",
      "*********** Support RESULTS ***********\n",
      "Epoch 10:\n",
      "\tAccuracy: 0.900\n",
      "\tPrecision: 0.904\n",
      "\tRecall: 0.900\n",
      "\tF-1 Score: 0.900\n",
      "*********** Average RESULTS ***********\n",
      "Epoch 10:\n",
      "\tAccuracy: 0.867\n",
      "\tPrecision: 0.872\n",
      "\tRecall: 0.867\n",
      "\tF-1 Score: 0.861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:07<00:00,  9.81it/s]\n",
      "100%|██████████| 40/40 [00:04<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Relevance RESULTS ***********\n",
      "Epoch 11:\n",
      "\tAccuracy: 0.833\n",
      "\tPrecision: 0.839\n",
      "\tRecall: 0.833\n",
      "\tF-1 Score: 0.823\n",
      "*********** Support RESULTS ***********\n",
      "Epoch 11:\n",
      "\tAccuracy: 0.850\n",
      "\tPrecision: 0.865\n",
      "\tRecall: 0.850\n",
      "\tF-1 Score: 0.848\n",
      "*********** Average RESULTS ***********\n",
      "Epoch 11:\n",
      "\tAccuracy: 0.842\n",
      "\tPrecision: 0.852\n",
      "\tRecall: 0.842\n",
      "\tF-1 Score: 0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:06<00:00, 10.53it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Relevance RESULTS ***********\n",
      "Epoch 12:\n",
      "\tAccuracy: 0.833\n",
      "\tPrecision: 0.839\n",
      "\tRecall: 0.833\n",
      "\tF-1 Score: 0.823\n",
      "*********** Support RESULTS ***********\n",
      "Epoch 12:\n",
      "\tAccuracy: 0.850\n",
      "\tPrecision: 0.865\n",
      "\tRecall: 0.850\n",
      "\tF-1 Score: 0.848\n",
      "*********** Average RESULTS ***********\n",
      "Epoch 12:\n",
      "\tAccuracy: 0.842\n",
      "\tPrecision: 0.852\n",
      "\tRecall: 0.842\n",
      "\tF-1 Score: 0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:06<00:00, 10.52it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 11.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Relevance RESULTS ***********\n",
      "Epoch 13:\n",
      "\tAccuracy: 0.833\n",
      "\tPrecision: 0.839\n",
      "\tRecall: 0.833\n",
      "\tF-1 Score: 0.823\n",
      "*********** Support RESULTS ***********\n",
      "Epoch 13:\n",
      "\tAccuracy: 0.850\n",
      "\tPrecision: 0.865\n",
      "\tRecall: 0.850\n",
      "\tF-1 Score: 0.848\n",
      "*********** Average RESULTS ***********\n",
      "Epoch 13:\n",
      "\tAccuracy: 0.842\n",
      "\tPrecision: 0.852\n",
      "\tRecall: 0.842\n",
      "\tF-1 Score: 0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/72 [00:00<00:38,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 7/72 [00:01<00:11,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 16/72 [00:02<00:09,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 19/72 [00:03<00:09,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 35/72 [00:05<00:05,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 36/72 [00:05<00:07,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 38/72 [00:06<00:08,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 55/72 [00:08<00:04,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 57/72 [00:09<00:04,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 63/72 [00:10<00:02,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 68/72 [00:11<00:00,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 70/72 [00:12<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:12<00:00,  5.69it/s]\n",
      " 10%|█         | 4/40 [00:00<00:06,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 12/40 [00:02<00:05,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/40 [00:03<00:06,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 21/40 [00:04<00:04,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 24/40 [00:05<00:04,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28/40 [00:06<00:03,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:07<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Accuracy: 0.8416666666666667\n",
      "Average Validation Precision: 0.8519345238095237\n",
      "Average Validation Recall: 0.8416666666666667\n",
      "Average Validation F1-Score: 0.8357808857808857\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.420 MB of 0.420 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Running Validation Accuracy</td><td>▁▄▅▅██▆▅▇▇▅▅▅</td></tr><tr><td>Average Running Validation F1-Score</td><td>▁▃▅▅██▆▅▇▇▅▅▅</td></tr><tr><td>Average Running Validation Precision</td><td>▁▆▅▆██▆▆██▆▆▆</td></tr><tr><td>Average Running Validation Recall</td><td>▁▄▅▅██▆▅▇▇▅▅▅</td></tr><tr><td>Average Validation Accuracy</td><td>▁</td></tr><tr><td>Average Validation F1-Score</td><td>▁</td></tr><tr><td>Average Validation Precision</td><td>▁</td></tr><tr><td>Average Validation Recall</td><td>▁</td></tr><tr><td>Relevance Running Validation Accuracy</td><td>▁▄▅▅▇█▄▄▇▇▇▇▇</td></tr><tr><td>Relevance Running Validation F1-Score</td><td>▁▃▅▅▇█▄▄▇▇▇▇▇</td></tr><tr><td>Relevance Running Validation Precision</td><td>▁▆▆▆▇█▅▅▇▇▇▇▇</td></tr><tr><td>Relevance Running Validation Recall</td><td>▁▄▅▅▇█▄▄▇▇▇▇▇</td></tr><tr><td>Support Running Validation Accuracy</td><td>▃▃▃▃▆▃█▆▆▆▁▁▁</td></tr><tr><td>Support Running Validation F1-Score</td><td>▃▃▃▃▆▃█▆▆▆▁▁▁</td></tr><tr><td>Support Running Validation Precision</td><td>▃▅▂▅▅▃█▅▅▅▁▁▁</td></tr><tr><td>Support Running Validation Recall</td><td>▃▃▃▃▆▃█▆▆▆▁▁▁</td></tr><tr><td>eval/loss</td><td>██▃▃▁▁▁▁▁▁▂▂▂▂▃▃▄▄▅▅▅▅▅▅▅▅</td></tr><tr><td>eval/runtime</td><td>▇▇▁▁▄▄▆▆▅▅▄▄▃▃▃▃▅▅██▆▆██▅▅</td></tr><tr><td>eval/samples_per_second</td><td>▂▂██▅▅▃▃▄▄▅▅▆▆▆▆▄▄▁▁▃▃▁▁▃▃</td></tr><tr><td>eval/steps_per_second</td><td>▁▁██▅▅▁▁▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁▅▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▁▁▂▂▂▁▁▁▁▁▂▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▅███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>████▆▆▅▅▅▅▄▄▄▄▄▄▄▃▄▃▃▂▂▃▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Running Validation Accuracy</td><td>0.84167</td></tr><tr><td>Average Running Validation F1-Score</td><td>0.83578</td></tr><tr><td>Average Running Validation Precision</td><td>0.85193</td></tr><tr><td>Average Running Validation Recall</td><td>0.84167</td></tr><tr><td>Average Validation Accuracy</td><td>0.84167</td></tr><tr><td>Average Validation F1-Score</td><td>0.83578</td></tr><tr><td>Average Validation Precision</td><td>0.85193</td></tr><tr><td>Average Validation Recall</td><td>0.84167</td></tr><tr><td>Relevance Running Validation Accuracy</td><td>0.83333</td></tr><tr><td>Relevance Running Validation F1-Score</td><td>0.82308</td></tr><tr><td>Relevance Running Validation Precision</td><td>0.83929</td></tr><tr><td>Relevance Running Validation Recall</td><td>0.83333</td></tr><tr><td>Support Running Validation Accuracy</td><td>0.85</td></tr><tr><td>Support Running Validation F1-Score</td><td>0.84848</td></tr><tr><td>Support Running Validation Precision</td><td>0.86458</td></tr><tr><td>Support Running Validation Recall</td><td>0.85</td></tr><tr><td>eval/loss</td><td>1.21877</td></tr><tr><td>eval/runtime</td><td>9.8714</td></tr><tr><td>eval/samples_per_second</td><td>4.052</td></tr><tr><td>eval/steps_per_second</td><td>0.507</td></tr><tr><td>total_flos</td><td>4.34079269954519e+16</td></tr><tr><td>train/epoch</td><td>12.63158</td></tr><tr><td>train/global_step</td><td>60</td></tr><tr><td>train/grad_norm</td><td>0.47412</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.8214</td></tr><tr><td>train_loss</td><td>0.94704</td></tr><tr><td>train_runtime</td><td>788.4443</td></tr><tr><td>train_samples_per_second</td><td>1.427</td></tr><tr><td>train_steps_per_second</td><td>0.076</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/myj7rgrb' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/myj7rgrb</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 4 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_230628-myj7rgrb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xuk6m3gt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232020-xuk6m3gt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/xuk6m3gt' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/xuk6m3gt' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/xuk6m3gt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/xuk6m3gt' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/xuk6m3gt</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232020-xuk6m3gt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run xuk6m3gt errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run xuk6m3gt errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zdv9xp79 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232031-zdv9xp79</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/zdv9xp79' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/zdv9xp79' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/zdv9xp79</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/zdv9xp79' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/zdv9xp79</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232031-zdv9xp79/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run zdv9xp79 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run zdv9xp79 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ulu4cl75 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232042-ulu4cl75</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/ulu4cl75' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/ulu4cl75' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/ulu4cl75</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/ulu4cl75' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/ulu4cl75</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232042-ulu4cl75/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run ulu4cl75 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ulu4cl75 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ry0kr20b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232102-ry0kr20b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/ry0kr20b' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/ry0kr20b' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/ry0kr20b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/ry0kr20b' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/ry0kr20b</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232102-ry0kr20b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run ry0kr20b errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ry0kr20b errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o8rt54yd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232113-o8rt54yd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/o8rt54yd' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/o8rt54yd' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/o8rt54yd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/o8rt54yd' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/o8rt54yd</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232113-o8rt54yd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run o8rt54yd errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run o8rt54yd errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rgltopo1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232129-rgltopo1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/rgltopo1' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/rgltopo1' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/rgltopo1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/rgltopo1' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/rgltopo1</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232129-rgltopo1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run rgltopo1 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run rgltopo1 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9rw4vtqi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232149-9rw4vtqi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/9rw4vtqi' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/9rw4vtqi' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/9rw4vtqi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/9rw4vtqi' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/9rw4vtqi</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232149-9rw4vtqi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 9rw4vtqi errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 9rw4vtqi errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o8w6igmz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232200-o8w6igmz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/o8w6igmz' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/o8w6igmz' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/o8w6igmz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/o8w6igmz' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/o8w6igmz</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232200-o8w6igmz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run o8w6igmz errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run o8w6igmz errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5hmm0ano with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232220-5hmm0ano</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/5hmm0ano' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/5hmm0ano' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/5hmm0ano</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/5hmm0ano' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/5hmm0ano</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232220-5hmm0ano/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 5hmm0ano errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 5hmm0ano errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 472sp9z7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232250-472sp9z7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/472sp9z7' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/472sp9z7' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/472sp9z7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/472sp9z7' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/472sp9z7</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232250-472sp9z7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 472sp9z7 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 472sp9z7 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: euw0qdx4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232259-euw0qdx4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/euw0qdx4' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/euw0qdx4' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/euw0qdx4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/euw0qdx4' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/euw0qdx4</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232259-euw0qdx4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run euw0qdx4 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run euw0qdx4 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n2joxnkr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232310-n2joxnkr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/n2joxnkr' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/n2joxnkr' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/n2joxnkr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/n2joxnkr' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/n2joxnkr</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232310-n2joxnkr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run n2joxnkr errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run n2joxnkr errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eqs17f97 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232330-eqs17f97</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/eqs17f97' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/eqs17f97' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/eqs17f97</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/eqs17f97' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/eqs17f97</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232330-eqs17f97/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run eqs17f97 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run eqs17f97 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lhljry6q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232341-lhljry6q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/lhljry6q' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/lhljry6q' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/lhljry6q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/lhljry6q' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/lhljry6q</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232341-lhljry6q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run lhljry6q errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run lhljry6q errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 53tb67f2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232352-53tb67f2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/53tb67f2' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/53tb67f2' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/53tb67f2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/53tb67f2' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/53tb67f2</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232352-53tb67f2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 53tb67f2 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 53tb67f2 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fs96wz11 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_alpha: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneftune: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trank: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kmGPT/wandb/run-20240706_232403-fs96wz11</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/fs96wz11' target=\"_blank\">Hyperband Sweep</a></strong> to <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/sweeps/tf4q3apm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/fs96wz11' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/fs96wz11</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth: Fast Mistral patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA A40. Max memory: 44.352 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Hyperband Sweep</strong> at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/fs96wz11' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep/runs/fs96wz11</a><br/> View project at: <a href='https://wandb.ai/morgridge/Porpoise%202.0%20Sweep' target=\"_blank\">https://wandb.ai/morgridge/Porpoise%202.0%20Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240706_232403-fs96wz11/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run fs96wz11 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "    model, tokenizer = dispatch_model.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "    return FastLlamaModel.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "    model_patcher.pre_patch()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "    init_name, function = patch_linear_scaling(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "    function = inspect.getsource(attention_module.__init__)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "    lines, lnum = getsourcelines(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run fs96wz11 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_12521/1031498692.py\", line 4, in run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = FastLanguageModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\", line 172, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = dispatch_model.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 317, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return FastLlamaModel.from_pretrained(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\", line 1130, in from_pretrained\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_patcher.pre_patch()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\", line 274, in pre_patch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     init_name, function = patch_linear_scaling(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py\", line 615, in patch_linear_scaling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     function = inspect.getsource(attention_module.__init__)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = getsourcelines(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     lines, lnum = findsource(object)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise OSError('could not get source code')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m OSError: could not get source code\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep = sweep_config, project = \"Porpoise 2.0 Sweep\")\n",
    "\n",
    "wandb.agent(sweep_id, function = run, count = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "48b28458b5844e6289a668125f6baaf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74ebdf4619fb46f980d875cce6d764ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "908166e01f834c55a4edeb30045ce49c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "939ea3533459424aab71593aac6d76cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cca30912cc6f45dabd4a8917b94e34fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_939ea3533459424aab71593aac6d76cc",
      "placeholder": "​",
      "style": "IPY_MODEL_74ebdf4619fb46f980d875cce6d764ba",
      "value": "0.035 MB of 0.035 MB uploaded\r"
     }
    },
    "d19d664486b4460ba8d71ca26fbcc35f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_908166e01f834c55a4edeb30045ce49c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e5169fdcd78643819dfd415087779161",
      "value": 1
     }
    },
    "e5169fdcd78643819dfd415087779161": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ee7f42a1fc0e4e67bfb38456037a5df6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cca30912cc6f45dabd4a8917b94e34fd",
       "IPY_MODEL_d19d664486b4460ba8d71ca26fbcc35f"
      ],
      "layout": "IPY_MODEL_48b28458b5844e6289a668125f6baaf1"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
